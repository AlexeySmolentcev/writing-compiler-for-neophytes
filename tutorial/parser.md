# Теория компиляторов для неофитов

## Синтаксический анализатор

[Лексический анализатор <](lexer.md)
[Содержание](content.md)

-------

### Построение контекстно-свободной грамматики на примерах

Ранее рассмотренная регулярная грамматика хороша для поиска подстрок,
чисел в строке, проверке корректности ввода email и т.п.,
однако она недостаточно выразительна, чтобы описать синтаксис 
нетривиального языка программирования.
Например, регулярная грамматика не может описать язык
[правильных скобочных последовательностей](https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%B0%D0%B2%D0%B8%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F_%D1%81%D0%BA%D0%BE%D0%B1%D0%BE%D1%87%D0%BD%D0%B0%D1%8F_%D0%BF%D0%BE%D1%81%D0%BB%D0%B5%D0%B4%D0%BE%D0%B2%D0%B0%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C).
Чтобы это доказать, вспомним, что каждой регулярной грамматике
сопоставляется конечный автомат.
Если конечный автомат сгенерировал последовательность из нескольких открывающих скобок,
то чтобы получить правильную скобочную последовательность автомат должен сохранить
точное число открывающих скобок.
Так как автомат может сохранить информацию только в виде текущего состояния,
а число состояний конечно, то автомат не может сохранить число открывающих скобок,
которое может быть произвольно велико, а значит ни один конечный автомат
не может генерировать правильные скобочные последовательности.
Более формальное доказательство можно привести, опираясь на
[лемму о накачке](https://ru.wikipedia.org/wiki/%D0%9B%D0%B5%D0%BC%D0%BC%D0%B0_%D0%BE_%D1%80%D0%B0%D0%B7%D1%80%D0%B0%D1%81%D1%82%D0%B0%D0%BD%D0%B8%D0%B8).

Чтобы задать язык арифметических выражений, 
[БНФ](https://ru.wikipedia.org/wiki/Форма_Бэкуса_—_Наура) запись грамматики
и синтаксис многих языков программирования, достаточно воспользоваться
контекстно-свободной грамматикой (CFG).
Правила в CFG имеют в левой части ровно один символ и он нетерминал.
Это значит, что при выводе слова нужно заменять в частично выведенной строке
последовательно по одному нетреминальному символу на правые части правил,
причес символы заменяются независимо друг от друга, независимо от контекста.
Слово из контекстно-свобоюного языка можно разбить на подстроки, 
которые можно свернуть в нетерминальные символы,
а вся строка сворачивается в стартовый символ.

Покажем, как можно построить грамматику для арифметических выражений.
Пусть нетерминал `<number>` для числа уже определен каким-либо образом
(на практике числа собирает лексер согласно регулярной грамматике).
Определим нетерминал `<exp>`, который может раскрываться в выражения,
содержащие для начала только сложение.

```ABNF
<exp> ::= <number>      ; 1
<exp> ::= <exp> + <exp> ; 2
```

Мы пронумеровали правила, чтобы помечать узлы дерева разрбора,
согласно какому правилу была сделана подстановка.
Будем обозначать узлы дерева разбора соединением
нетерминала и номера правила подстановка для нетерминала,
например, `exp2` значит, что `<exp>` было заменено по правилу `2` на 
`<exp> + <exp>`, т.е. у этого узла будет два потомка, оба нетерминалы `<exp>`,
терминал `+` в дереве не отражается, так как он одназначно определен правилом `2`.

Согласно вышеприведенной грамматике
строка `1+2+3` может быть выведена согласно любому из двух деревьев разбора

```
exp2(exp1,exp2(exp1,exp1))
exp2(exp2(exp1,exp1),exp1)
```

что соответствует двум способам расстановки скобок `1+(2+3)` и `(1+2)+3`
соответственно.
Хотя для сложения оба выражения дают один результат,
для упрощения анализа коду, улучшения его читаемости
и увеличения скорости работы синтаксического анализатора
желательно, чтобы все слова в языке выводились единственным образом,
т.е. чтобы грамматика было *однозначной*.
Чтобы сделать нашу грамматику однозначной, мы должны зафиксировать
*ассоциативность*, т.е. порядок расстановки скобок.
Расстановка скобок `1+(2+3)` соответствует *правой ассоциативности*,
а расстановка `(1+2)+3` - *левой ассоциативности*.
Так как сложение является *ассоциативной* операцией, 
т.е. ее можно задать и лево- и правоассоциативной, 
то для большей содержательности примера добавим в грамматику вычитание.
Так как согласно традиционному прочтению

```
1-1-1=(1-1)-1=-1
```

то вычитание левоассоциативно.
Чтобы ввести ассоциативность в грамматику, нужно сделать
нетерминалы слева и справа от операции разными,
и делать рекурсию по левому операнду для левой ассоциативности,
и по правому - для правой.
Таким образом мы получаем следующую грамматику для сложения и вычитания:

```ABNF
<exp> ::= <exp> + <expa> ; 1
<exp> ::= <exp> - <expa> ; 2
<exp> ::= <expa>         ; 3
<expa> ::= <number>
```

Тогда строка `1-2+3` разбирается однозначно как
`exp1(exp2(exp3(expa),expa),expa)`.
При вычислении значения выражения нетерминалы `<exp>` и `<expa>`
можно не разделять, поэтому обычно их объединяют в AST, как мы увидим в следующих уроках,
однако для задания правильно ассоциативности два разных нетерминала необходимы.
Многие генератры синтаксических анализаторов могут автоматически генерировать
вспомогательные нетерминалы, программисту же остается только задатать
приоритеты операций и ассоциативность, но мы проделаем все шаги явно.

Добавим в грамматику умножение и деление, которые сделаем левоассоциативными:

```ABNF
<exp> ::= <exp> + <expa> ; 1
<exp> ::= <exp> - <expa> ; 2
<exp> ::= <expa>         ; 3
<exp> ::= <exp> * <expa> ; 5
<exp> ::= <exp> / <expa> ; 6
<expa> ::= <number>
```

Однако наша наивная попытка дает для выражения `1+2/3` неправильное дерево разбора
`exp6(exp1(exp3(expa),expa),expa)`,
т.е. скобки расставляются без приоритета операций `(1+2)/3`.
Чтобы ввести приоритет нам потребуются дополнительные нетерминалы,
причем нетерминалы для любой операции могут выражаться только через
нетерминалы для операций с более высоким приоритетом:

```ABNF
<exp> ::= <exp> + <expa> ; 1
<exp> ::= <exp> - <expa> ; 2
<exp> ::= <expa>         ; 3
<expa> ::= <expa> * <expb> ; 1
<expa> ::= <expa> / <expb> ; 2
<expa> ::= <expb>           ; 3
<expb> ::= <number>
```

Согласно новой грамматике никакое подвыражение с корнем `<expa>` 
не может содержать `<exp>`, т.е. сложение и вычитание всегда считаются после 
умножения и деления. 
Теперь для строки `1+2/3` мы получаем правильно дерево разбора:

```
exp1(exp3(expa3(expb)),exp3(expa2(expa3(expb),expa3(expb))))
```

Как мы видим, дерево разбора содержит много вспомогательных узлов
`exp3`, `expa3`, которые не несут смысловой нагрузки, кроме расстановки скобой,
поэтому из AST эти узлы удалают.

Добавим теперь в наши арифметические выражения скобки.
Скобки всегда встречвются парой, поэтому и добавляться они должны парой
в одном правиле.
Скобки имеют наивысший приоритет, поэтому правило для скобок должно быть
на том же уровне, что и `<number>`.
Внутри скобок разрешены любые операции, поэтому нужно сослаться на 
нетерминал `<exp>`.

```ABNF
<exp> ::= <exp> + <expa>   ; 1
<exp> ::= <exp> - <expa>   ; 2
<exp> ::= <expa>           ; 3
<expa> ::= <expa> * <expb> ; 1
<expa> ::= <expa> / <expb> ; 2
<expa> ::= <expb>          ; 3
<expb> ::= <number>        ; 1
<expb> ::= ( <exp> )       ; 2
```

Разберем предыдущее выражение, но теперь расставим скобки явно:
`(1+2)/3`, тогда дерево разбора принимает вид:

```
exp3(expa2(expa3(expb2(exp1(exp3(expa3(expb1)),expa3(expb1)))),expb1))
```

В качестве другого примера CFG определим БНФ через саму себя.
БНФ состоит из последовательности правил, разделенный символом (или несколькими)
конца строки `<new line>`.
Последовательность задается правилами вида

```ABNF
<regexp> ::= <regexp> <rule> <new line>
<regexp> ::=
```

или

```ABNF
<BNF> ::= <rule> <new line> <regexp>
<BNF> ::=
```

отличающимися только способом группировки правил.
Каждое правило представляет собой левую и правую часть,
разделенную символами `::=`, которые мы обозначим через нетерминал 
`<separator>`:

```ABNF
<rule> ::= <left> <separator> <right>
```

Левая часть в CFG может содержать только нетерминал:

```ABNF
<left> ::= <nonterminal>
```

Правая часть может содержать несколько выражений, разделенных 
символом `|`, который мы спрячем в нетерминал `<bar>`:

```ABNF
<right> ::= <exp> <bar> <right>
<right> ::= <exp>
```

Правила для `<right>` напоминают правила для `<BNF>`,
так как это тоже список, однако список для `<right>` не пустой,
а список для `<BNF>` может быть пустым (что возможно, хотя и не интересно,
так как пустая грамматика не будет порождать ни одного слова).

Каждое выражение в правой части правила представляет собой цепочку нетерминалов
и терминалов, причем цепочка может быть пустой, следовательно:

```ABNF
<exp> ::= <terminal> <exp>
<exp> ::= <nonterminal> <exp>
<exp> ::=
```

Следуя такого рода рассуждениям, вы можете построить грамматики для большинства
языков программирования.
Рассмотрим в качестве последнего примера грамматику для регулярных выражений.
Регулярное выражение представляет собой цепочку литералов,
над которыми применяются несколько операций, и для группировки которых
применяются скобки, т.е. все элементы конструкции нам знакомы.
Самый низкий приоритет имеет операция объединения (или)
регулярных выражений, записываемая в *инфиксном* виде (т.е. между операндами) 
с символом операции `|`, который мы обозначим нетерминалом `<bar>`.

```ABNF
<regexp> ::= <group>
<regexp> ::= <group> <bar> <regexp>
```

Остальные операции *постфиксные* (т.е. записываются после аргумента), 
поэтому определим их так:

```ABNF
<group> ::= <term>
<group> ::= <group> +
<group> ::= <group> *
<group> ::= <group> ?
```

Наконец примитивными частями регулярными выражения являются либо 
последовательности литералов,
либо регулярные выражения, заключенные в скобки:

```ABNF
<term> ::= 
<term> ::= <literal> <term>
<term> ::= ( <regexp> )
```

Литералы на практике группируются с помощью лексера, поэтому с точки зрения CFG
они являются терминалами.

### Семантические действия

Само по себе дерево разбора редко представляет интерес,
как правило нас интересует "смысл" разбираемого выражения,
т.е. семантика.
Семантика обычно задается *семантическими действиями*,
т.е. действиями, выполняемым для каждого узла дерева разбора.
Узлам дерева разбора приписываются некоторые значения,
выражающие "смысл" узла (в более общем подходе это может быть один 
или несколько атрибутов).
Семантические действия позволяют вычислять значения узлов
через значения потомков.
Традиционно значание самого узла в семантическом действии обозначают `$$`,
а значения потомков нумеруются по порядку `$1`, `$2`,..
Сами семантические действия часто записывают в фигурных скобках после правил.
Например, если "смыслом" арифметического выражения считать его числовое значение,
то семантические действия для грамматики арифметических выражений можно определить следующим
образом:

```ABNF
<exp> ::= <exp> + <expa>   { $$=$1+$3 } ; символ + участвует в нумерации
<exp> ::= <exp> - <expa>   { $$=$1-$3 }
<exp> ::= <expa>           { $$=$1 } ; действие по умолчанию, часто опускается
<expa> ::= <expa> * <expb> { $$=$1*$3 }
<expa> ::= <expa> / <expb> { $$=$1/$3 }
<expa> ::= <expb>          
<expb> ::= <number>        
<expb> ::= ( <exp> )       { $$=$2 }
```

Если же "смыслом" выражения будет алгоритм вычисления выражения,
то семантические действия должны конструировать абстрактное синтаксическое дерево:

```ABNF
<exp> ::= <exp> + <expa>   { $$=Plus($1,$3) } ; символ + участвует в нумерации
<exp> ::= <exp> - <expa>   { $$=Minus($1,$3) }
<exp> ::= <expa>           { $$=$1 } ; действие по умолчанию, часто опускается
<expa> ::= <expa> * <expb> { $$=Mult($1,$3) }
<expa> ::= <expa> / <expb> { $$=Div($1,$3) }
<expa> ::= <expb>
<expb> ::= <number>
<expb> ::= ( <exp> )       { $$=$2 }
```

Здесь мы обозначили через `Plus`, `Minus`, `Mult`, `Div` конструкторы для
узлов сложения, вычитания, умножения и деления.

В качестве другого примера рассмотрим семантические действия для
конструирования конченого автомата для регулярных выражений,
используя комбинаторы из лабораторной работы 3.

```ABNF
<regexp> ::= <group>                { $$=$1 }
<regexp> ::= <group> <bar> <regexp> { $$=Union($1, $3) }
<group> ::= <term>                  { $$=$1 }
<group> ::= <group> +               { $$=Plus($1) }
<group> ::= <group> *               { $$=Star($1) }
<group> ::= <group> ?               { $$=Option($1) }
<term> ::=                          { $$=Literal("") }
<term> ::= <literal> <term>         { $$=Concatenate(Literal($1),$2) }
<term> ::= ( <regexp> )             { $$=$2 }
```

### Разбор контекстно-свободной грамматики

В приверах выше мы строили деревья разбора (т.е. проводили
синтаксический анализ) опираясь на свой опыт и универсальный человеческий разум.
Однако при написании компилятора эту работу должна делать машина,
причем сложность разбора должна быть наименьшей возможной,
так как исходные коды программ могут быть очень и очень большими.
Минимальная сложность синтаксического анализатора
в большинстве случае `O(n)`, где `n` - длина разбираемого слова (исходного кода),
так как дерево разбора зависит от каждого символа в слове.
Посмотрим, каким образом можно достичь такой производительности.

Существуют два основных способа синтаксического разбора: сверху-вниз
или снизу-вверх.
При разборе сверху-вниз мы исходим из того, что корнем дерева
разбора обязательно будет стартовый символ.
Затем мы должны решить, по какому правилу грамматики нужно сделать подстановку
для стартового символа.
Например, согласно нашей грамматике для арифметических выражений,
мы имеем три способа замены стартового символа `<exp>`,
предположим, что мы сделали замену по правилу `1`,
тогда наш стартовый символ раскрылся в `<exp>+<expa>`.
Теперь мы должны каким-то образом раскрыть символ `<exp>`
в начале этого выражения.
Предположим, что мы сделали это по правилу `2`,
тогда мы получаем частично выведенную строку
`<exp>-<expa>+<expa>` и верхние два узла дерева разбора
`exp1(exp2(exp,expa),expa)`.
Эту процедуру мы должны повторять до тех пор, пока в частично
выведенной строке не останутся одни терминалы, после чего
строку нужно сравнить с данной.
Если строки совпадут, то разбор завершен успешно, в противном случае
нам необходимо рассмотреть другие варианты раскрытия правил.
Наример, если мы разбираем строку `1-2/3`, то сделанный ранее выбор
замен очевидно ошибочен, и последующие действия к успеху не приведут.
Нетривиальная часть синтаксического анализа как раз состоит в том,
чтобы сделать компьютеру очевидным то, что очевидно человеку.

Наиболее простой способ синтаксического анализа сверху-вниз реализуется
рекурсивным спуском.
В этом случае парсер (синтаксический анализатор) делает на каждом уровне
предположения на счет делаемой замены, формирует очередной уровень дерева,
после чего рекурсивно вызывает себя для каждого потомка.
Если предположить, что все правила имеют `k` вариантов, то
каждый уровень рекурсии увеличивает число рассматриваемых вариантов в `k`
раз, тем самым делая сложность алгоритма экспоненциальной.
На практике экспоненциальная сложность неприемлема, однако
возможны простые оптимизации, делающие алгоритм практически полезным.
В частности, если в результате подстановок мы получили в начале частично выведенной
строке терминал, то этот терминал нужно сразу сравнить с первым символом слова,
что позволит отбросить многие ошибочные варианты разбора,
то же нужно проделать со вторым символом и т.д.
Например, если в какой-то момент мы использовали правило для скобок,
то следующим ожидаемым симполом должны быть открывающая скобка,
и анализируя вход, мы можем легко проверить, так ли это.

При рекурсивном спуске мы отбрасываем заведомо ошибочные варианты
сравнением ожидаемых терминалов с фактически имеющимися,
однако можно начать использовать информацию о терминалах в начале разбираемого
слова раньше, не делая подстановки.
Так мы можем найти все символы, с которых могут начинаться нетерминалы.
Если каждое правило для нетерминала соответствует своему префиксу,
то при выборе правила для подстановки мы может сделать однозначный выбор
в пользу одного из правил глядя на префикс разбираемой строки.
Так работает `LL(k)` парсер, где `k` обозначает число символов разбираемой
строки, на которое можно подглядывать (глубина предпросмотра).
В связи с быстрым ростом размера таблиц парсера с ростом `k`,
на практике обычно используется один символ для предпрасмотра.
Более совершенным является `LL(*)` парсер, который вместо строк фиксированной
длины использует для предпросмотра регулярные выражения.
`LL(*)` парсер реализует популярный генератор парсеров
[ANTLR](http://www.antlr.org/).

Парсер `LL` легко реализовать, однако на практике его не слишком удобно
использовать, так как он плохо работает с леворекурсивными правилами,
возникающими, например, для левоассоциативных операций.
Действительно, леворекурсивное правило имеет префиксом теже символы,
что и другие правила для того же нетерминала,
т.е. `LL` парсер не может однозначно выбрать замену.
Леворекурсивные правила можно переписать в праворекурсивном виде для парсинга,
а правильный вид дерева восстанавливать в семинтических действиях или
после завершения парсинга, для чего в частности удобно использовать
[Атрибутные транслирующие грамматики](https://neerc.ifmo.ru/wiki/index.php?title=%D0%90%D1%82%D1%80%D0%B8%D0%B1%D1%83%D1%82%D0%BD%D1%8B%D0%B5_%D1%82%D1%80%D0%B0%D0%BD%D1%81%D0%BB%D0%B8%D1%80%D1%83%D1%8E%D1%89%D0%B8%D0%B5_%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0%D1%82%D0%B8%D0%BA%D0%B8).
Однако этот подход усложняет алгоритм, что лишает `LL` парсер основного достоинства - простоты.

Подход снизу-вверх напротив пытается собирать дерево разбора
начиная с листьев.
Например, при разборе арифметических выражений парсер может
сразу выделить нетерминалы для чисел, нетерминалы для скобок и т.п.,
не разбирая выражений, частями которых они являются.
Более формально, при разборе снизу-вверх
парсер на каждом шаге либо сдвигается на один символ
(читает один символ из разбираемой строки),
либо делает свертку (объединяет уже прочитанные символы в нетреминалы).
Например, при разборе выражения `1+2/3`, парсер должен сделать
следующие шаги (чертой `|` мы разделяем уже прочитанную часть и остаток строки):

```
| 1+2/3
1 | +2/3 ; сдвиг
<expb> | +2/3 ; свертка по правилу expb 1
<expa> | +2/3 ; свертка по правилу expb 3
<exp> | +2/3 ; свертка по правилу exp 3
<exp>+ | 2/3 ; сдвиг
<exp>+2 | /3 ; сдвиг
<exp>+<expb> | /3 ; свертка по правилу expb 1
<exp>+<expa> | /3 ; свертка по правилу expa 3
<exp>+<expa>/ | 3 ; сдвиг
<exp>+<expa>/3 | ; сдвиг
<exp>+<expa>/<expb> | ; свертка по правилу expb 1
<exp>+<expa> | ; свертка по правилу expa 2
<exp> | ; свертка по правилу exp 1
```

На каждом шаге парсер должен принять решение: делать сдвиг
или сворачивать по одному из правил.
Наивный парсер будет перебирать все возможные варианты,
количество которых растет экспоненциально с число читаемых символов.
Если же удастся каким-то образом одназначно определить,
когда и по какому правилу нужно делать свертку,
то можно делать разбор за линейное время.
Не для любой грамматики это возможно,
однако для ряда грамматик это удается сделать с помощью `LR` парсера.

Парсер `LR` состоит из стека, на который записываются
уже свернутые символы и мимволы из потока ввода,
и из конечного автомата, принимающего решение,
когда нужно делать свертку.
Чтобы построить автомат для `LR` парсера, мы отслеживаем для всех правил,
какую часть правила нам удается разобрать, читая все возможные терминалы.
Для примера рассмотрим простую грамматику, чтобы избежать построения большого
автомата:

```ABNF
<S> ::= <S> + <A> ; 1
<S> ::= <A>       ; 2
<A> ::= 1         ; 3
```

Перед чтением каких-либо символов автомат ожидает, что разбирается стартовый символ `<S>`.
Для стартового символа есть два правила, выпишем их,
пометив символом `^` место правила, соответствующее следующему ожидаемому терминалу.
В самом начале, естественно, чтение начинается сначала:

```ABNF
; состояние 1
<S> ::= ^ <S> + <A>
<S> ::= ^ <A>
```

Так как следующим ожидаемым символом может быть нетерминал `<A>`,
то нам нужно добавить и правила для `<A>` в начальное состояние

```ABNF
; состояние 1
<S> ::= ^ <S> + <A>
<S> ::= ^ <A>
<A> ::= ^ 1
```

Если мы прочитаем символ `1`, то в правиле для `<A>` можно сделать сдвиг
на один символ, тем самым второе состояние содержит свернутое правило для `<A>`:

```ABNF
; состояние 2
<A> ::= 1 ^
```

Так как во втором состоянии разбор одного из правил закончен, 
то это состояние остановочное и соответствует свертке по правилу 3 из грамматики.
Свернув нетерминал `<A>`, мы можем сдвинуть его во втором правиле в состоянии 1,
получая состояние 3:

```ABNF
; состояние 3
<S> ::= <A> ^
```

Это тоже остановочное состояние, отвечает свертке по правилу 2.

Из первого состояния остался нерассмотренным еще один переход
по нетерминалу `<S>`, по которму мы попадаем в состояние 4:

```ABNF
; состояние 4
<S> ::= <S> ^ + <A>
```

Из четвертого состояния возможен только переход по символу `+`
в состояние 5:

```ABNF
; состояние 5
<S> ::= <S> + ^ <A>
```

В состоянии 5 опять следующим символом нетерминал,
поэтому нам нужно добавить все способы его раскрытия:

```ABNF
; состояние 5
<S> ::= <S> + ^ <A>
<A> ::= ^ 1
```

Прочитав `1` мы сдвигаемся во втором правиле,
и переходим в состояние для свернутого `<A>`,
которое мы уже видели, и присвоили ему номер 2.
Наконец, по нетерминалу `<A>` мы попадаем в остановочное 
состояние со свернутым по первому правилу грамматики `<S>`:

```ABNF
; состояние 6
<S> ::= <S> + <A> ^
```

Перечислим все переходы для каждого состояния в одной талице:

```
1: '1' -> 2, <A> -> 3, <S> -> 4
2: *3
3: *2
4: '+' -> 5
5: '1' -> 2, <A> -? 6
6: *1
```

Здесь мы использовали следующие обозначения:

```
номер состояния: `терминал` -> номер состояние для перехода
номер состояния: <нетерминал> -> номер состояние для перехода
номер состояния: * номер правило грамматики для свертки
```

Как только мы построили этот автомат, мы можем игнорировать способ
построения и содержание состояний, важны лишь их номера и переходы.

Покажем, как воспользоваться `LR` автоматом.
Будем последовательно читать терминалы из рабираемой строки
и делать переходы в автомате, согласно читаемыи символами.
Как только мы попадем в остановочное состояние,
мы сделаем свертку согласно сопоставленному состоянию правилу.
При свертке мы снимает со стека перечисленные в правой части правила
символы, а вместо них кладем на стек символ из левой части правила.
Затем мы перезапускаем автомат с вершины стека.
Если мы опять попадем в остановочное состоние, то снова делаем свертку.
Если мы достигнем вершины стека, то снова начнем читать терминалы из
разбираемой строки.
Попробуем разобрать строку `1+1+1`.
Будем записывать состояние стека слева от символа `|`,
а непроичтанные симаолы разбираемой строки - справа.
Номера состояний будем писать в квадратных скобках.
После каждой свертке будем писать состояние с новой строки:

```
(1) | 1+1+1 ; до начала работы
(1) 1 (2) | +1+1 ; свертка по правилу 3
(1) <A> (3) | +1+1 ; свертка по правилу 2
(1) <S> (4) + (5) 1 (2) | +1 ; свертка по правилу 3
(1) <S> (4) + (5) <A> (6) | +1 ; свертка по правилу 1
(1) <S> (4) + (5) 1 (2) | ; свертка по правилу 3
(1) <S> (4) + (5) <A> (6) | ; свертка по правилу 1
(1) <S> | ; вся строка свернута в стартовый символ = успех
```

Рассмотренная нами ситуация очень проста,
на практике могут возникнуть конфликты:

* свертка-свертка, если в одном состоянии возможны свертки по двум правилам;
* свертка-сдвиг, если из остановочного состояния возможен переход в другое состояние.

При возникновении любого из конфликтов использование `LR` парсера
невозможно, однако можно использовать `GLR` парсер,
который отслеживает все допустимые варианты сдвигов и сверток.
`GLR` парсер вообще говоря имеет не линейную сложность,
однако на практике быстродействие парсера падает мало.

Для разрешения конфликтов можно использовать символы для предпросмотра,
как мы это делали для `LL(k)` парсера.
`LR` с предпросмотром называется `LR(k)` парсер.
Способ построения автомата для `LR(k)` парсера
такой же, как и для `LR`, однако нужно делать переходы
по `k+1` символу, причем только первый из них может быть
нетерминалом.
Чтоды однозначно составить состояние автомата, необходимо
для каждого правила хранить `k` символов строки, идущей после
нетерминала из левой части правила.
Добавление символов для предпросмотра значительно увеличивает
размер автомата, поэтому вместо `LR(k)` парсера обычно
используют `LALR(k)` парсер, в котором символы для предпросмотра
используются только при необходимости.
Один из самых известных генераторов парсер 
[GNU Bison](https://ru.wikipedia.org/wiki/GNU_Bison),
может генерировать `LALR(1)` и `GLR` парсеры.

Перечисленные парсеры конструируются по четким правилам,
поэтому создание этих парсеров можно автоматизировать.
Программы, автоматические синтезирующие парсеры,
называют генераторами парсеров.
Обзор самых известных генераторов парсеров можно найти
на [соответствующей странице](https://en.wikipedia.org/wiki/Comparison_of_parser_generators) 
Википедии.


### Литература

1. Dick Grune and Ceriel J.H. Jacobs. 
[Parsing Techniques.](https://dickgrune.com/Books/PTAPG_2nd_Edition/) 
Springer US: VU University Amsterdam (2008).
1.  Альфред Ахо, Рави Сети, Джеффри Ульман. 
[Компиляторы. Принципы, технологии, инструменты.](https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BC%D0%BF%D0%B8%D0%BB%D1%8F%D1%82%D0%BE%D1%80%D1%8B:_%D0%BF%D1%80%D0%B8%D0%BD%D1%86%D0%B8%D0%BF%D1%8B,_%D1%82%D0%B5%D1%85%D0%BD%D0%BE%D0%BB%D0%BE%D0%B3%D0%B8%D0%B8_%D0%B8_%D0%B8%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B)
Издательство Вильямс, 2001.

-------

[Лексический анализатор <](lexer.md)
[Содержание](content.md)